{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12078295,"sourceType":"datasetVersion","datasetId":7603229}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-08T14:00:51.168458Z","iopub.execute_input":"2025-06-08T14:00:51.168737Z","iopub.status.idle":"2025-06-08T14:00:54.408396Z","shell.execute_reply.started":"2025-06-08T14:00:51.168714Z","shell.execute_reply":"2025-06-08T14:00:54.406785Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/life-expectancy-scaled/life_expectancy_scaled.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndf = pd.read_csv(\"/kaggle/input/life-expectancy-scaled/life_expectancy_scaled.csv\")\n\nX = df.drop(columns=[\"Life expectancy\"])\ny = df[\"Life expectancy\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#Linear Regression\nX_train_sm = sm.add_constant(X_train)\nX_test_sm = sm.add_constant(X_test)\nmodel_lr = sm.OLS(y_train, X_train_sm).fit()\ny_pred_lr = model_lr.predict(X_test_sm)\n\n#Random Forest Regressor\nmodel_rf = RandomForestRegressor(random_state=42)\nmodel_rf.fit(X_train, y_train)\ny_pred_rf = model_rf.predict(X_test)\n\nprint(\"Linear Regression (statsmodels):\")\nprint(model_lr.summary())\n\nprint(\"\\nRandom Forest Regressor:\")\nprint(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\nprint(f\"R² Score: {r2_score(y_test, y_pred_rf):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T14:00:54.410478Z","iopub.execute_input":"2025-06-08T14:00:54.411276Z","iopub.status.idle":"2025-06-08T14:01:03.186048Z","shell.execute_reply.started":"2025-06-08T14:00:54.411249Z","shell.execute_reply":"2025-06-08T14:01:03.184836Z"}},"outputs":[{"name":"stdout","text":"Linear Regression (statsmodels):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        Life expectancy   R-squared:                       0.957\nModel:                            OLS   Adj. R-squared:                  0.957\nMethod:                 Least Squares   F-statistic:                     1618.\nDate:                Sun, 08 Jun 2025   Prob (F-statistic):               0.00\nTime:                        14:01:03   Log-Likelihood:                 355.59\nNo. Observations:                2350   AIC:                            -645.2\nDf Residuals:                    2317   BIC:                            -455.0\nDf Model:                          32                                         \nCovariance Type:            nonrobust                                         \n===================================================================================================\n                                      coef    std err          t      P>|t|      [0.025      0.975]\n---------------------------------------------------------------------------------------------------\nconst                              -6.2910      0.071    -88.946      0.000      -6.430      -6.152\nAdult Mortality                    -0.0266      0.006     -4.197      0.000      -0.039      -0.014\nAlcohol                            -0.0052      0.006     -0.869      0.385      -0.017       0.006\nHepatitis B                        -0.0192      0.005     -3.746      0.000      -0.029      -0.009\nMeasles                            -0.0097      0.005     -1.918      0.055      -0.020       0.000\nBMI                                -0.0114      0.006     -1.972      0.049      -0.023   -6.19e-05\nunder-five deaths                  -0.0013      0.006     -0.199      0.842      -0.014       0.011\nPolio                               0.0078      0.006      1.289      0.198      -0.004       0.020\nTotal expenditure               -5.943e-05      0.005     -0.013      0.990      -0.009       0.009\nDiphtheria                          0.0251      0.006      3.906      0.000       0.012       0.038\nHIV/AIDS                           -0.0582      0.005    -10.719      0.000      -0.069      -0.048\nGDP                                 0.0009      0.005      0.177      0.860      -0.009       0.011\nPopulation                         -0.0004      0.006     -0.078      0.938      -0.011       0.010\nIncome composition of resources     0.0012      0.008      0.153      0.878      -0.014       0.017\nSchooling                           0.0290      0.008      3.482      0.001       0.013       0.045\nThinness Average                   -0.0059      0.006     -0.944      0.345      -0.018       0.006\nStatus_encoded                      0.0156      0.016      0.998      0.318      -0.015       0.046\nCountry_encoded                     0.0965      0.001     88.814      0.000       0.094       0.099\nYear_2000                          -0.6110      0.019    -32.050      0.000      -0.648      -0.574\nYear_2001                          -0.5844      0.018    -32.755      0.000      -0.619      -0.549\nYear_2002                          -0.5739      0.018    -31.245      0.000      -0.610      -0.538\nYear_2003                          -0.5676      0.018    -31.546      0.000      -0.603      -0.532\nYear_2004                          -0.5380      0.018    -29.543      0.000      -0.574      -0.502\nYear_2005                          -0.4818      0.018    -27.469      0.000      -0.516      -0.447\nYear_2006                          -0.4471      0.017    -25.781      0.000      -0.481      -0.413\nYear_2007                          -0.4239      0.017    -24.472      0.000      -0.458      -0.390\nYear_2008                          -0.3741      0.017    -21.633      0.000      -0.408      -0.340\nYear_2009                          -0.3285      0.017    -19.090      0.000      -0.362      -0.295\nYear_2010                          -0.3225      0.017    -18.828      0.000      -0.356      -0.289\nYear_2011                          -0.2623      0.017    -15.220      0.000      -0.296      -0.228\nYear_2012                          -0.2351      0.017    -14.026      0.000      -0.268      -0.202\nYear_2013                          -0.2012      0.017    -12.024      0.000      -0.234      -0.168\nYear_2014                          -0.1652      0.017     -9.490      0.000      -0.199      -0.131\nYear_2015                          -0.1744      0.017    -10.326      0.000      -0.208      -0.141\n==============================================================================\nOmnibus:                      520.302   Durbin-Watson:                   1.936\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            14992.117\nSkew:                           0.364   Prob(JB):                         0.00\nKurtosis:                      15.352   Cond. No.                     1.80e+17\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 3.55e-28. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\nRandom Forest Regressor:\nMSE: 0.0264\nR² Score: 0.9725\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Most influential Predictors : HIV/AIDS , Adult Mortality , Diphtheria(DTP3) , Schooling , Hepatitis B , BMI , Country Encoded , Year .\n\nAlthough the linear model identifies significant linear predictors, the random forest (which captures non-linear and interaction effects) achieved a higher R² (0.9725 vs 0.957).\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nimport numpy as np\n\n# Linear Regression (statsmodels) predictions are already in y_pred_lr\n# Random Forest predictions are already in y_pred_rf\n\n# ---- Linear Regression Evaluation ----\nlr_r2 = r2_score(y_test, y_pred_lr)\nlr_mae = mean_absolute_error(y_test, y_pred_lr)\nlr_mse = mean_squared_error(y_test, y_pred_lr)\nlr_rmse = np.sqrt(lr_mse)\n\nprint(\"\\nLinear Regression Performance:\")\nprint(f\"R²: {lr_r2:.4f}\")\nprint(f\"MAE: {lr_mae:.4f}\")\nprint(f\"MSE: {lr_mse:.4f}\")\nprint(f\"RMSE: {lr_rmse:.4f}\")\n\n# ---- Random Forest\nrf_r2 = r2_score(y_test, y_pred_rf)\nrf_mae = mean_absolute_error(y_test, y_pred_rf)\nrf_mse = mean_squared_error(y_test, y_pred_rf)\nrf_rmse = np.sqrt(rf_mse)\n\nprint(\"\\nRandom Forest Regressor Performance:\")\nprint(f\"R²: {rf_r2:.4f}\")\nprint(f\"MAE: {rf_mae:.4f}\")\nprint(f\"MSE: {rf_mse:.4f}\")\nprint(f\"RMSE: {rf_rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T14:04:36.379505Z","iopub.execute_input":"2025-06-08T14:04:36.379876Z","iopub.status.idle":"2025-06-08T14:04:36.394830Z","shell.execute_reply.started":"2025-06-08T14:04:36.379852Z","shell.execute_reply":"2025-06-08T14:04:36.393747Z"}},"outputs":[{"name":"stdout","text":"\nLinear Regression Performance:\nR²: 0.9623\nMAE: 0.1237\nMSE: 0.0361\nRMSE: 0.1901\n\nRandom Forest Regressor Performance:\nR²: 0.9725\nMAE: 0.0978\nMSE: 0.0264\nRMSE: 0.1625\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"R-squared(Proportion of variance explained) : Random Forest Regressor has a greater R-squared.\n\nMAE(Average of absolute errors) : Random Forest Regressor has lower MAE.\n\nMSE(Mean of Squared errors) : Forest Regressor has lower MSE.\n\nRMSE(Root of MSE) : Forest Regressor has lower RMSE.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
